{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OrdinalEncoder\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder,OneHotEncoder, LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.linear_model import LogisticRegression\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-13T12:46:27.564831Z","iopub.execute_input":"2023-08-13T12:46:27.565335Z","iopub.status.idle":"2023-08-13T12:46:29.006978Z","shell.execute_reply.started":"2023-08-13T12:46:27.565291Z","shell.execute_reply":"2023-08-13T12:46:29.005626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Baseline Model** *(0.66846)*","metadata":{}},{"cell_type":"code","source":"# train=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# train.head()\n# test=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# train.dtypes\n\n\n# X = train[['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText']]\n# y = train['sentiment']\n# from sklearn.dummy import DummyClassifier\n# dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n# dummy_clf.fit(X, y)\n# dummy_clf.score(X, y)\n# dummy_clf.predict(y)\n\n\n# y_pred = pd.DataFrame(dummy_clf.predict(test))\n# y_pred.columns=[\"sentiment\"]\n# y_pred.index.name=\"id\"\n# y_pred.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.008924Z","iopub.execute_input":"2023-08-13T12:46:29.009232Z","iopub.status.idle":"2023-08-13T12:46:29.015369Z","shell.execute_reply.started":"2023-08-13T12:46:29.009204Z","shell.execute_reply":"2023-08-13T12:46:29.014070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Baseline Model** *(0.66846)*","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\n\n\n# train=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# train.head()\n# test=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# train.dtypes\n# X = train[['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText']]\n# y_train = train['sentiment']\n# label_encoder = LabelEncoder()\n# y_train = label_encoder.fit_transform(y_train)\n# X_test = test\n# majority_class = np.bincount(y_train).argmax()\n# y_pred = np.full(len(X_test), majority_class)\n# y_pred_inv = label_encoder.inverse_transform(y_pred)\n# test['sentiment'] = y_pred_inv\n# test.index.name = \"id\"\n# submission_df = test[['sentiment']]\n# submission_df.to_csv('submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.016675Z","iopub.execute_input":"2023-08-13T12:46:29.016966Z","iopub.status.idle":"2023-08-13T12:46:29.034727Z","shell.execute_reply.started":"2023-08-13T12:46:29.016940Z","shell.execute_reply":"2023-08-13T12:46:29.033234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression** *(0.83286)*","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\n# from scipy.sparse import hstack\n\n\n# df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# X = df.drop(['sentiment'], axis=1)  # Features\n# y = df['sentiment']  # Target variable\n# cat_features = ['movieid', 'reviewerName']\n# encoder = OneHotEncoder(handle_unknown='ignore')\n# X_encoded_train = encoder.fit_transform(X[cat_features])\n# X['reviewText'].fillna('', inplace=True)\n# text_feature = 'reviewText'\n# vectorizer = TfidfVectorizer()\n# X_text_train = vectorizer.fit_transform(X[text_feature])\n# X_combined_train = hstack((X_encoded_train, X_text_train))\n# model = LogisticRegression(max_iter=250)\n# model.fit(X_combined_train, y)\n# test_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# X_test = test_df\n# X_encoded_test = encoder.transform(X_test[cat_features])\n# X_test['reviewText'].fillna('', inplace=True)\n# X_text_test = vectorizer.transform(X_test[text_feature])\n# X_combined_test = hstack((X_encoded_test, X_text_test))\n# y_pred = model.predict(X_combined_test)\n# test_df['sentiment'] = y_pred\n# test_df.index.name = \"id\"\n# submission_df = test_df[['sentiment']]\n# submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.037301Z","iopub.execute_input":"2023-08-13T12:46:29.037804Z","iopub.status.idle":"2023-08-13T12:46:29.050729Z","shell.execute_reply.started":"2023-08-13T12:46:29.037761Z","shell.execute_reply":"2023-08-13T12:46:29.049361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.051974Z","iopub.execute_input":"2023-08-13T12:46:29.053028Z","iopub.status.idle":"2023-08-13T12:46:29.072596Z","shell.execute_reply.started":"2023-08-13T12:46:29.052976Z","shell.execute_reply":"2023-08-13T12:46:29.070943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression with Cross-Validation** *(0.80413)*","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import cross_val_predict\n# from scipy.sparse import hstack\n\n# # Read the training dataset\n# train_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# test_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# X_train = train_df.drop(['sentiment'], axis=1)\n# y_train = train_df['sentiment']\n\n# X_train['reviewText'].fillna('', inplace=True)\n# test_df['reviewText'].fillna('', inplace=True)\n# text_feature = 'reviewText'\n# vectorizer = TfidfVectorizer()\n# train_matrix = vectorizer.fit_transform(X_train[text_feature])\n# test_matrix = vectorizer.transform(test_df[text_feature])\n# X_combined_train = hstack((X_train['isFrequentReviewer'].values.reshape(-1, 1), train_matrix))\n# logreg = LogisticRegression(max_iter=1000)\n# y_pred_train = cross_val_predict(logreg, X_combined_train, y_train, cv=5)\n# X_combined_test = hstack((test_df['isTopCritic'].values.reshape(-1, 1), test_matrix))\n# logreg.fit(X_combined_train, y_train)\n# y_pred_test = logreg.predict(X_combined_test)\n# submission_test_df = pd.DataFrame({'id': test_df.index, 'sentiment': y_pred_test})\n# submission_test_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.075056Z","iopub.execute_input":"2023-08-13T12:46:29.075465Z","iopub.status.idle":"2023-08-13T12:46:29.087527Z","shell.execute_reply.started":"2023-08-13T12:46:29.075430Z","shell.execute_reply":"2023-08-13T12:46:29.086596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**KNN without HPT** *(0.6867)*","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\n# from scipy.sparse import hstack\n# from sklearn.preprocessing import OneHotEncoder\n\n\n# df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# X = df.drop(['sentiment'], axis=1)  # Features\n# y = df['sentiment']  # Target variable\n\n# cat_features = ['movieid', 'reviewerName']\n# text_feature = 'reviewText'\n\n# X['reviewText'].fillna('', inplace=True)\n\n# # Encode categorical features using OneHotEncoder\n# encoder = OneHotEncoder(handle_unknown='ignore')\n# X_encoded = encoder.fit_transform(X[cat_features])\n\n# # Vectorize text feature using TfidfVectorizer\n# vectorizer = TfidfVectorizer()\n# X_text = vectorizer.fit_transform(X[text_feature])\n\n# # Combine encoded categorical features and text feature\n# X_combined = hstack((X_encoded, X_text))\n\n# # Split the data into training and test sets\n# X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n\n# # Create and train the KNN model\n# model = KNeighborsClassifier()\n# model.fit(X_train, y_train)\n\n# # Make predictions on test data\n# y_pred = model.predict(X_test)\n\n# # Evaluate the accuracy of the model\n# accuracy = accuracy_score(y_test, y_pred)\n# print(\"Accuracy:\", accuracy)\n\n# # Load and preprocess the test data\n# test_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# test_df['reviewText'].fillna('', inplace=True)\n# X_encoded_test = encoder.transform(test_df[cat_features])\n# X_text_test = vectorizer.transform(test_df[text_feature])\n# X_combined_test = hstack((X_encoded_test, X_text_test))\n\n# # Make predictions on the test data\n# y_pred = model.predict(X_combined_test)\n\n# # Add the predictions to the test data\n# test_df['sentiment'] = y_pred\n# test_df.index.name = \"id\"\n# submission_df = test_df[['sentiment']]\n# submission_df.to_csv('submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.089413Z","iopub.execute_input":"2023-08-13T12:46:29.090098Z","iopub.status.idle":"2023-08-13T12:46:29.112093Z","shell.execute_reply.started":"2023-08-13T12:46:29.090062Z","shell.execute_reply":"2023-08-13T12:46:29.110195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**KNN with HPT** *(0.6802)*","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n# from sklearn.metrics import accuracy_score\n# from scipy.sparse import hstack\n# from sklearn.preprocessing import OneHotEncoder\n# import numpy as np\n\n# df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# X = df.drop(['sentiment'], axis=1)  # Features\n# y = df['sentiment']  # Target variable\n\n# cat_features = ['movieid', 'reviewerName']\n# text_feature = 'reviewText'\n\n# X['reviewText'].fillna('', inplace=True)\n\n# # Encode categorical features using OneHotEncoder\n# encoder = OneHotEncoder(handle_unknown='ignore')\n# X_encoded = encoder.fit_transform(X[cat_features])\n\n# # Vectorize text feature using TfidfVectorizer with max_features\n# vectorizer = TfidfVectorizer(max_features=5000)  # Set max_features to desired value\n# X_text = vectorizer.fit_transform(X[text_feature])\n\n# # Combine encoded categorical features and text feature\n# X_combined = hstack((X_encoded, X_text))\n\n# # Split the data into training and test sets\n# X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n\n# # Define the parameter grid for randomized search\n# param_grid = {'n_neighbors': [2, 3, 4, 5]}  # Use a list of possible values\n\n# # Create the KNN model\n# knn = KNeighborsClassifier()\n\n# # Perform randomized search with cross-validation\n# randomized_search = RandomizedSearchCV(knn, param_grid, cv=5)\n# randomized_search.fit(X_train, y_train)\n\n# # Get the best parameter values and best score\n# best_k = randomized_search.best_params_['n_neighbors']\n# best_score = randomized_search.best_score_\n\n# print(\"Best k:\", best_k)\n# print(\"Best score:\", best_score)\n\n# # Create and train the KNN model with the best k value\n# model = KNeighborsClassifier(n_neighbors=best_k)\n# model.fit(X_train, y_train)\n\n# # Make predictions on test data\n# y_pred = model.predict(X_test)\n\n# # Evaluate the accuracy of the model\n# accuracy = accuracy_score(y_test, y_pred)\n# print(\"Accuracy:\", accuracy)\n\n# # Load and preprocess the test data\n# test_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# test_df['reviewText'].fillna('', inplace=True)\n# X_encoded_test = encoder.transform(test_df[cat_features])\n# X_text_test = vectorizer.transform(test_df[text_feature])\n# X_combined_test = hstack((X_encoded_test, X_text_test))\n\n# # Make predictions on the test data\n# y_pred = model.predict(X_combined_test)\n\n# # Add the predictions to the test data\n# test_df['sentiment'] = y_pred\n# test_df.index.name = \"id\"\n# submission_df = test_df[['sentiment']]\n# submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.113939Z","iopub.execute_input":"2023-08-13T12:46:29.115312Z","iopub.status.idle":"2023-08-13T12:46:29.136133Z","shell.execute_reply.started":"2023-08-13T12:46:29.115250Z","shell.execute_reply":"2023-08-13T12:46:29.134187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SVM** *(0.8169)*","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.svm import LinearSVC\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\n# from scipy.sparse import hstack\n# from sklearn.preprocessing import OneHotEncoder\n# import numpy as np\n\n# df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# X = df.drop(['sentiment'], axis=1)  # Features\n# y = df['sentiment']  # Target variable\n\n# cat_features = ['movieid', 'reviewerName']\n# text_feature = 'reviewText'\n\n# X['reviewText'].fillna('', inplace=True)\n\n# # Encode categorical features using OneHotEncoder\n# encoder = OneHotEncoder(handle_unknown='ignore')\n# X_encoded = encoder.fit_transform(X[cat_features])\n\n# # Vectorize text feature using TfidfVectorizer with max_features\n# vectorizer = TfidfVectorizer(max_features=5000)  # Set max_features to desired value\n# X_text = vectorizer.fit_transform(X[text_feature])\n\n# # Combine encoded categorical features and text feature\n# X_combined = hstack((X_encoded, X_text))\n\n# # Split the data into training and test sets\n# X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n\n# # Create and train the LinearSVC model\n# model = LinearSVC()\n# model.fit(X_train, y_train)\n\n# # Make predictions on test data\n# y_pred = model.predict(X_test)\n\n# # Evaluate the accuracy of the model\n# accuracy = accuracy_score(y_test, y_pred)\n# print(\"Accuracy:\", accuracy)\n\n# # Load and preprocess the test data\n# test_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# test_df['reviewText'].fillna('', inplace=True)\n# X_encoded_test = encoder.transform(test_df[cat_features])\n# X_text_test = vectorizer.transform(test_df[text_feature])\n# X_combined_test = hstack((X_encoded_test, X_text_test))\n\n# # Make predictions on the test data\n# y_pred = model.predict(X_combined_test)\n\n# # Add the predictions to the test data\n# test_df['sentiment'] = y_pred\n# test_df.index.name = \"id\"\n# submission_df = test_df[['sentiment']]\n# submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.137786Z","iopub.execute_input":"2023-08-13T12:46:29.138145Z","iopub.status.idle":"2023-08-13T12:46:29.161195Z","shell.execute_reply.started":"2023-08-13T12:46:29.138112Z","shell.execute_reply":"2023-08-13T12:46:29.159892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decision Tree** *(0.6783)*","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.tree import DecisionTreeClassifier\n# from scipy.sparse import hstack\n# from sklearn.preprocessing import OneHotEncoder\n\n# df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# X = df.drop(['sentiment'], axis=1)  # Features\n# y = df['sentiment']  # Target variable\n\n# cat_features = ['movieid', 'reviewerName']\n# text_feature = 'reviewText'\n\n# X['reviewText'].fillna('', inplace=True)\n\n# encoder = OneHotEncoder(handle_unknown='ignore')\n# X_encoded = encoder.fit_transform(X[cat_features])\n\n# vectorizer = TfidfVectorizer()\n# X_text = vectorizer.fit_transform(X[text_feature])\n\n# X_combined = hstack((X_encoded, X_text))\n\n# model = DecisionTreeClassifier()\n# model.fit(X_combined, y)\n\n# test_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# test_df['reviewText'].fillna('', inplace=True)\n# X_encoded_test = encoder.transform(test_df[cat_features])\n# X_text_test = vectorizer.transform(test_df[text_feature])\n# X_combined_test = hstack((X_encoded_test, X_text_test))\n\n# y_pred = model.predict(X_combined_test)\n# test_df['sentiment'] = y_pred\n# test_df.index.name = \"id\"\n# submission_df = test_df[['sentiment']]\n# submission_df.to_csv('submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.164442Z","iopub.execute_input":"2023-08-13T12:46:29.165000Z","iopub.status.idle":"2023-08-13T12:46:29.184940Z","shell.execute_reply.started":"2023-08-13T12:46:29.164970Z","shell.execute_reply":"2023-08-13T12:46:29.183570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bagging** *(0.7273)*","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn.ensemble import BaggingClassifier\n# from scipy.sparse import hstack\n# from sklearn.preprocessing import OneHotEncoder\n\n# df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# X = df.drop(['sentiment'], axis=1)  # Features\n# y = df['sentiment']  # Target variable\n\n# cat_features = ['movieid', 'reviewerName']\n# text_feature = 'reviewText'\n\n# X['reviewText'].fillna('', inplace=True)\n\n# # Encode categorical features using OneHotEncoder\n# encoder = OneHotEncoder(handle_unknown='ignore')\n# X_encoded = encoder.fit_transform(X[cat_features])\n\n# # Vectorize text feature using TfidfVectorizer with max_features\n# vectorizer = TfidfVectorizer(max_features=5000)  # Set max_features to desired value\n# X_text = vectorizer.fit_transform(X[text_feature])\n\n# # Combine encoded categorical features and text feature\n# X_combined = hstack((X_encoded, X_text))\n\n# # Create and train the BaggingClassifier with Decision Tree base estimator\n# base_estimator = DecisionTreeClassifier()\n# model = BaggingClassifier(base_estimator=base_estimator)\n# model.fit(X_combined, y)\n\n# # Load and preprocess the test data\n# test_df = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# test_df['reviewText'].fillna('', inplace=True)\n# X_encoded_test = encoder.transform(test_df[cat_features])\n# X_text_test = vectorizer.transform(test_df[text_feature])\n# X_combined_test = hstack((X_encoded_test, X_text_test))\n\n# # Make predictions on the test data\n# y_pred = model.predict(X_combined_test)\n\n# # Add the predictions to the test data\n# test_df['sentiment'] = y_pred\n# test_df.index.name = \"id\"\n# submission_df = test_df[['sentiment']]\n# submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.187242Z","iopub.execute_input":"2023-08-13T12:46:29.187652Z","iopub.status.idle":"2023-08-13T12:46:29.204230Z","shell.execute_reply.started":"2023-08-13T12:46:29.187623Z","shell.execute_reply":"2023-08-13T12:46:29.203523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Experiment with Movies.CSV**","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import OrdinalEncoder\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n# from sklearn.ensemble import RandomForestClassifier\n# import pandas as pd\n# from sklearn.compose import ColumnTransformer\n# from sklearn.impute import SimpleImputer\n# from sklearn.preprocessing import StandardScaler, OrdinalEncoder,OneHotEncoder, LabelEncoder, MinMaxScaler\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.pipeline import Pipeline\n# from sklearn.linear_model import LogisticRegression\n# from scipy.sparse import hstack, csr_matrix\n# from scipy.sparse import hstack\n# import pandas as pd\n# from sklearn.linear_model import LogisticRegression\n# import pandas as pd\n# from sklearn.preprocessing import FunctionTransformer\n# from sklearn.base import BaseEstimator, TransformerMixin\n# from scipy import sparse","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.205926Z","iopub.execute_input":"2023-08-13T12:46:29.206424Z","iopub.status.idle":"2023-08-13T12:46:29.227112Z","shell.execute_reply.started":"2023-08-13T12:46:29.206399Z","shell.execute_reply":"2023-08-13T12:46:29.226430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# origtrain=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# movies=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/movies.csv')\n# origtest=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# origtest['isFrequentReviewer']=origtest['isTopCritic']\n# print(\"Shape of movies.csv: \",movies.shape)\n# print(\"Movie info: \")\n# movies.info()\n# print(\"Train info: \")\n# origtrain.info()\n# print(\"Test info: \")\n# origtest.info()\n# movies=movies.drop_duplicates(subset='movieid')\n# train = pd.merge(origtrain, movies, on='movieid', how='inner')\n# ytrain=train['sentiment']\n# train=train.drop(['sentiment'],axis=1)\n# train.info()\n# test = pd.merge(origtest, movies, on='movieid', how='inner')\n# test.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.228111Z","iopub.execute_input":"2023-08-13T12:46:29.228735Z","iopub.status.idle":"2023-08-13T12:46:29.245537Z","shell.execute_reply.started":"2023-08-13T12:46:29.228711Z","shell.execute_reply":"2023-08-13T12:46:29.244455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# positive_count = origtrain[\"sentiment\"].eq(\"POSITIVE\").sum()\n# negative_count = origtrain[\"sentiment\"].eq(\"NEGATIVE\").sum()\n\n# sizes = [positive_count, negative_count]\n# labels = ['Positive', 'Negative']\n# colors = ['#66b3ff', '#ff9999']\n\n# plt.figure(figsize=(6, 6))\n# plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n# plt.title('Sentiment Ratio: Positives vs. Negatives')\n# plt.axis('equal')  \n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.247181Z","iopub.execute_input":"2023-08-13T12:46:29.248195Z","iopub.status.idle":"2023-08-13T12:46:29.261052Z","shell.execute_reply.started":"2023-08-13T12:46:29.248156Z","shell.execute_reply":"2023-08-13T12:46:29.260207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**#Visualize Key Statistics**","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# imputer = SimpleImputer(strategy='mean')\n# columns_to_impute = ['audienceScore', 'runtimeMinutes']\n# train[columns_to_impute] = imputer.fit_transform(train[columns_to_impute])\n\n# sns.pairplot(train, hue='rating')\n# plt.show()\n\n# numerical_stats = train.describe()\n# print(numerical_stats)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.262496Z","iopub.execute_input":"2023-08-13T12:46:29.262956Z","iopub.status.idle":"2023-08-13T12:46:29.284796Z","shell.execute_reply.started":"2023-08-13T12:46:29.262926Z","shell.execute_reply":"2023-08-13T12:46:29.283363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**#EDA**","metadata":{}},{"cell_type":"code","source":"# missing_values = origtrain.isnull().sum()\n# print(missing_values)\n# sns.heatmap(origtrain.isnull(), cbar=False, cmap='viridis')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.286019Z","iopub.execute_input":"2023-08-13T12:46:29.287567Z","iopub.status.idle":"2023-08-13T12:46:29.301799Z","shell.execute_reply.started":"2023-08-13T12:46:29.287524Z","shell.execute_reply":"2023-08-13T12:46:29.300437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing_values = train.isnull().sum()\n# print(missing_values)\n\n# sns.heatmap(train.isnull(), cbar=False, cmap='viridis')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.303099Z","iopub.execute_input":"2023-08-13T12:46:29.304599Z","iopub.status.idle":"2023-08-13T12:46:29.317809Z","shell.execute_reply.started":"2023-08-13T12:46:29.304550Z","shell.execute_reply":"2023-08-13T12:46:29.316997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing_values = test.isnull().sum()\n# print(missing_values)\n\n# sns.heatmap(test.isnull(), cbar=False, cmap='viridis')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.318912Z","iopub.execute_input":"2023-08-13T12:46:29.320573Z","iopub.status.idle":"2023-08-13T12:46:29.337260Z","shell.execute_reply.started":"2023-08-13T12:46:29.320524Z","shell.execute_reply":"2023-08-13T12:46:29.335662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**#Feature Engineering**","metadata":{}},{"cell_type":"code","source":"\n# popular_threshold = 75\n# train['isPopularMovie'] = train['audienceScore'] >= popular_threshold\n# train['isPopularMovie'] = train['isPopularMovie'].astype(int)\n\n# print(train['isPopularMovie'].value_counts())\n\n# plt.figure(figsize=(8, 6))\n# plt.hist(train['audienceScore'], bins=30, color='skyblue')\n# plt.xlabel('Audience Score')\n# plt.ylabel('Frequency')\n# plt.title('Distribution of Audience Scores')\n# plt.grid(True)\n# plt.show()\n\n# plt.figure(figsize=(8, 6))\n# sns.boxplot(x='isPopularMovie', y='audienceScore', data=train)\n# plt.xlabel('isPopularMovie')\n# plt.ylabel('Audience Score')\n# plt.title('Relationship between isPopularMovie and Audience Score')\n# plt.grid(True)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.339456Z","iopub.execute_input":"2023-08-13T12:46:29.339966Z","iopub.status.idle":"2023-08-13T12:46:29.352141Z","shell.execute_reply.started":"2023-08-13T12:46:29.339930Z","shell.execute_reply":"2023-08-13T12:46:29.351252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numerical_cols = train.select_dtypes(include=['float64']).columns\n# categorical_cols = train.select_dtypes(include=['object', 'bool']).columns\n\n# train[numerical_cols] = train[numerical_cols].fillna(train[numerical_cols].mean())\n# train[categorical_cols] = train[categorical_cols].fillna('')\n\n# encoder = OrdinalEncoder()\n# train[categorical_cols] = encoder.fit_transform(train[categorical_cols])\n# model = RandomForestClassifier(random_state=42)\n# model.fit(train, ytrain)\n# feature_importances = model.feature_importances_\n# all_cols = list(train.columns)\n# importance_df = pd.DataFrame({'Feature': all_cols, 'Importance': feature_importances})\n\n# importance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# plt.figure(figsize=(10, 6))\n# plt.bar(importance_df['Feature'], importance_df['Importance'])\n# plt.xlabel('Features')\n# plt.ylabel('Importance')\n# plt.xticks(rotation=90)\n# plt.title('Feature Importances')\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.353333Z","iopub.execute_input":"2023-08-13T12:46:29.354003Z","iopub.status.idle":"2023-08-13T12:46:29.369712Z","shell.execute_reply.started":"2023-08-13T12:46:29.353970Z","shell.execute_reply":"2023-08-13T12:46:29.368781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# origtrain=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\n# movies=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/movies.csv')\n# origtest=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\n# origtest['isFrequentReviewer']=origtest['isTopCritic']\n# origtest=origtest.drop(['isTopCritic'],axis=1)\n# movies=movies.drop_duplicates(subset='movieid')\n# train = pd.merge(origtrain, movies, on='movieid', how='left')\n# train = train.dropna(subset=['reviewText'])\n# ytrain=train['sentiment']\n# train=train.drop(['sentiment'],axis=1)\n# test = pd.merge(origtest, movies, on='movieid', how='left')\n# features=['movieid','reviewerName','isFrequentReviewer','reviewText','audienceScore','rating','runtimeMinutes','genre','originalLanguage','director','boxOffice']\n# train=train[features].copy()\n# train.info()\n# test=test[features].copy()\n# test.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.371059Z","iopub.execute_input":"2023-08-13T12:46:29.371484Z","iopub.status.idle":"2023-08-13T12:46:29.391448Z","shell.execute_reply.started":"2023-08-13T12:46:29.371448Z","shell.execute_reply":"2023-08-13T12:46:29.390423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numerical_pipeline = Pipeline([\n#     ('imputer', SimpleImputer(strategy='mean')),\n#     ('scaler', StandardScaler())\n# ])\n\n# categorical_pipeline = Pipeline([\n#     ('imputer', SimpleImputer(strategy='constant', fill_value=''))\n# ])\n\n# numerical_cols = ['audienceScore','runtimeMinutes']\n# boolean_cols = ['isFrequentReviewer']\n# categorical_cols = ['movieid', 'reviewerName', 'reviewText','rating','genre','originalLanguage','director','boxOffice']\n\n\n\n# preprocessor = ColumnTransformer(transformers=[\n#     ('num', numerical_pipeline, numerical_cols),\n#     ('cat', categorical_pipeline, categorical_cols)\n# ], remainder='passthrough')  # Include the remaining columns\n\n# # Apply label encoding for boolean columns\n# train['isFrequentReviewer'] = train['isFrequentReviewer'].astype(int)\n# test['isFrequentReviewer'] = test['isFrequentReviewer'].astype(int)\n\n# #Use LabelEncoder\n\n# X_train_transformed = preprocessor.fit_transform(train)\n# X_test_transformed = preprocessor.transform(test)\n\n# train_preprocessed = pd.DataFrame(X_train_transformed, columns=numerical_cols + categorical_cols + boolean_cols)\n# test_preprocessed = pd.DataFrame(X_test_transformed, columns=numerical_cols + categorical_cols + boolean_cols)\n# print(train_preprocessed.isnull().sum())\n# print(test_preprocessed.isnull().sum())\n# print(\"Train shape: \", train_preprocessed.shape)\n# print(\"Test shape: \", test_preprocessed.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.392704Z","iopub.execute_input":"2023-08-13T12:46:29.393412Z","iopub.status.idle":"2023-08-13T12:46:29.406878Z","shell.execute_reply.started":"2023-08-13T12:46:29.393383Z","shell.execute_reply":"2023-08-13T12:46:29.405586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.svm import LinearSVC\n\n# train_preprocessed['audienceScore'] = train_preprocessed['audienceScore'].astype(float)\n# test_preprocessed['audienceScore'] = test_preprocessed['audienceScore'].astype(float)\n# train_preprocessed['runtimeMinutes'] = train_preprocessed['runtimeMinutes'].astype(float)\n# test_preprocessed['runtimeMinutes'] = test_preprocessed['runtimeMinutes'].astype(float)\n# ngram_range = (1, 1)  # This specifies to use unigrams and bigrams\n# C = 1.2\n# vector = TfidfVectorizer(ngram_range=ngram_range)\n# vector.fit(train_preprocessed['movieid'] + ' ' + train_preprocessed['reviewerName'] + ' ' + train_preprocessed['reviewText'] + ' ' + train_preprocessed['rating'] + ' ' + train_preprocessed['genre'] + ' ' + train_preprocessed['originalLanguage'] + ' ' + train_preprocessed['director'] + ' ' + train_preprocessed['boxOffice'])\n\n# movieid_tfidf_train = vector.transform(train_preprocessed['movieid'])\n# reviewerName_tfidf_train = vector.transform(train_preprocessed['reviewerName'])\n# reviewText_tfidf_train = vector.transform(train_preprocessed['reviewText'])\n# rating_tfidf_train = vector.transform(train_preprocessed['rating'])\n# genre_tfidf_train = vector.transform(train_preprocessed['genre'])\n# originalLanguage_tfidf_train = vector.transform(train_preprocessed['originalLanguage'])\n# boxOffice_tfidf_train = vector.transform(train_preprocessed['boxOffice'])\n# director_tfidf_train = vector.transform(train_preprocessed['director'])\n# combined_data_train = hstack([train_preprocessed['audienceScore'].values.reshape(-1, 1),\n#                               train_preprocessed['runtimeMinutes'].values.reshape(-1, 1),\n#                               movieid_tfidf_train,\n#                               reviewerName_tfidf_train,\n#                               reviewText_tfidf_train,\n#                               rating_tfidf_train,\n#                               genre_tfidf_train,\n#                               originalLanguage_tfidf_train,\n#                              boxOffice_tfidf_train,\n#                              director_tfidf_train])\n\n# combined_train = pd.DataFrame.sparse.from_spmatrix(combined_data_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.408183Z","iopub.execute_input":"2023-08-13T12:46:29.408526Z","iopub.status.idle":"2023-08-13T12:46:29.429826Z","shell.execute_reply.started":"2023-08-13T12:46:29.408500Z","shell.execute_reply":"2023-08-13T12:46:29.428847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = LogisticRegression(C=C, max_iter=50000)\n# model.fit(combined_train, ytrain)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.431194Z","iopub.execute_input":"2023-08-13T12:46:29.431859Z","iopub.status.idle":"2023-08-13T12:46:29.452836Z","shell.execute_reply.started":"2023-08-13T12:46:29.431774Z","shell.execute_reply":"2023-08-13T12:46:29.451463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# movieid_tfidf_test = vector.transform(test_preprocessed['movieid'])\n# reviewerName_tfidf_test = vector.transform(test_preprocessed['reviewerName'])\n# reviewText_tfidf_test = vector.transform(test_preprocessed['reviewText'])\n# rating_tfidf_test = vector.transform(test_preprocessed['rating'])\n# genre_tfidf_test = vector.transform(test_preprocessed['genre'])\n# originalLanguage_tfidf_test = vector.transform(test_preprocessed['originalLanguage'])\n# boxOffice_tfidf_test = vector.transform(test_preprocessed['boxOffice'])\n# director_tfidf_test = vector.transform(test_preprocessed['director'])\n# combined_data_test = hstack([test_preprocessed['audienceScore'].values.reshape(-1, 1),\n#                              test_preprocessed['runtimeMinutes'].values.reshape(-1, 1),\n#                              movieid_tfidf_test,\n#                              reviewerName_tfidf_test,\n#                              reviewText_tfidf_test,\n#                              rating_tfidf_test,\n#                               genre_tfidf_test,\n#                               originalLanguage_tfidf_test,\n#                              boxOffice_tfidf_test,\n#                              director_tfidf_test\n#                             ])\n# combined_test = pd.DataFrame.sparse.from_spmatrix(combined_data_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.454296Z","iopub.execute_input":"2023-08-13T12:46:29.454653Z","iopub.status.idle":"2023-08-13T12:46:29.471140Z","shell.execute_reply.started":"2023-08-13T12:46:29.454629Z","shell.execute_reply":"2023-08-13T12:46:29.469798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# y_pred = model.predict(combined_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.473225Z","iopub.execute_input":"2023-08-13T12:46:29.473897Z","iopub.status.idle":"2023-08-13T12:46:29.491162Z","shell.execute_reply.started":"2023-08-13T12:46:29.473862Z","shell.execute_reply":"2023-08-13T12:46:29.490293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = LinearSVC(C=C,penalty='l2',tol=1e-4,max_iter=50000)\n#model.fit(combined_train, ytrain)\n#y_pred=model.predict(combined_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.492334Z","iopub.execute_input":"2023-08-13T12:46:29.493004Z","iopub.status.idle":"2023-08-13T12:46:29.506071Z","shell.execute_reply.started":"2023-08-13T12:46:29.492938Z","shell.execute_reply":"2023-08-13T12:46:29.504733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# origtest['sentiment'] = y_pred\n# origtest.index.name = \"id\"\n# submission_df = origtest[['sentiment']]\n# submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.513022Z","iopub.execute_input":"2023-08-13T12:46:29.513413Z","iopub.status.idle":"2023-08-13T12:46:29.522819Z","shell.execute_reply.started":"2023-08-13T12:46:29.513382Z","shell.execute_reply":"2023-08-13T12:46:29.521632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"origtrain=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')\nmovies=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/movies.csv')\norigtest=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\norigtest['isFrequentReviewer']=origtest['isTopCritic']\nprint(\"Shape of movies.csv: \",movies.shape)\nprint(\"Movie info: \")\nmovies.info()\nprint(\"Train info: \")\norigtrain.info()\nprint(\"Test info: \")\norigtest.info()\nmovies=movies.drop_duplicates(subset='movieid')\ntrain = pd.merge(origtrain, movies, on='movieid', how='inner')\nytrain=train['sentiment']\ntrain=train.drop(['sentiment'],axis=1)\ntrain.info()\ntest = pd.merge(origtest, movies, on='movieid', how='inner')\ntest.info()\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimputer = SimpleImputer(strategy='mean')\ncolumns_to_impute = ['audienceScore', 'runtimeMinutes']\ntrain[columns_to_impute] = imputer.fit_transform(train[columns_to_impute])\n\nsns.pairplot(train, hue='rating')\nplt.show()\n\nnumerical_stats = train.describe()\nprint(numerical_stats)\n\nmissing_values = origtrain.isnull().sum()\nprint(missing_values)\nsns.heatmap(origtrain.isnull(), cbar=False, cmap='viridis')\nplt.show()\n\nmissing_values = train.isnull().sum()\nprint(missing_values)\n\nsns.heatmap(train.isnull(), cbar=False, cmap='viridis')\nplt.show()\n\n\npopular_threshold = 75\ntrain['isPopularMovie'] = train['audienceScore'] >= popular_threshold\ntrain['isPopularMovie'] = train['isPopularMovie'].astype(int)\n\nprint(train['isPopularMovie'].value_counts())\n\nplt.figure(figsize=(8, 6))\nplt.hist(train['audienceScore'], bins=30, color='skyblue')\nplt.xlabel('Audience Score')\nplt.ylabel('Frequency')\nplt.title('Distribution of Audience Scores')\nplt.grid(True)\nplt.show()\n\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='isPopularMovie', y='audienceScore', data=train)\nplt.xlabel('isPopularMovie')\nplt.ylabel('Audience Score')\nplt.title('Relationship between isPopularMovie and Audience Score')\nplt.grid(True)\nplt.show()\n\nnumerical_cols = train.select_dtypes(include=['float64']).columns\ncategorical_cols = train.select_dtypes(include=['object', 'bool']).columns\n\ntrain[numerical_cols] = train[numerical_cols].fillna(train[numerical_cols].mean())\ntrain[categorical_cols] = train[categorical_cols].fillna('')\n\nencoder = OrdinalEncoder()\ntrain[categorical_cols] = encoder.fit_transform(train[categorical_cols])\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(train, ytrain)\nfeature_importances = model.feature_importances_\nall_cols = list(train.columns)\nimportance_df = pd.DataFrame({'Feature': all_cols, 'Importance': feature_importances})\n\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\nplt.figure(figsize=(10, 6))\nplt.bar(importance_df['Feature'], importance_df['Importance'])\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.xticks(rotation=90)\nplt.title('Feature Importances')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:46:29.524236Z","iopub.execute_input":"2023-08-13T12:46:29.525250Z","iopub.status.idle":"2023-08-13T12:47:57.460056Z","shell.execute_reply.started":"2023-08-13T12:46:29.525202Z","shell.execute_reply":"2023-08-13T12:47:57.459001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Final**","metadata":{}},{"cell_type":"code","source":"trainingData=pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv') # train.csv\nmoviesData = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/movies.csv') #movies.csv\ntestingData =pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv') #test.csv\n\nprint(\"Training Data shape: \",trainingData.shape)\nprint(\"Test Data shape: \",testingData.shape)\nprint(\"Movies Data shape: \",moviesData.shape)\n\n#--------Checking the info----------------\nprint(\"Training Data info: \",trainingData.info())\nprint(\"Test Data info: \",testingData.info())\nprint(\"Movies Data info: \",moviesData.info())\n\nprint(\"Nulls in Training Data:\\n\",trainingData.isnull().sum())\nprint()\nprint(\"Nulls in Testing Data:\\n\",testingData.isnull().sum())\nprint()\nprint(\"Nulls in Movies Data:\\n\",moviesData.isnull().sum())\n\ntrainingData['reviewText'].fillna(' ',inplace=True)\ntestingData['reviewText'].fillna(' ',inplace=True)\n\nprint(trainingData.isnull().sum())\nprint()\nprint(testingData.isnull().sum())\n\nprint(\"Movie IDs in train data: \",trainingData.movieid.count())\nprint(\"Unique movie IDs: \",trainingData.movieid.nunique())\nprint(\"Movie IDs in movie data: \",moviesData.movieid.count())\nprint(\"Unique movie IDs: \",moviesData.movieid.nunique())","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:47:57.461535Z","iopub.execute_input":"2023-08-13T12:47:57.461872Z","iopub.status.idle":"2023-08-13T12:47:59.437066Z","shell.execute_reply.started":"2023-08-13T12:47:57.461843Z","shell.execute_reply":"2023-08-13T12:47:59.435758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trainingData.describe())\nprint(testingData.describe())\nprint(moviesData.describe())","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:47:59.438553Z","iopub.execute_input":"2023-08-13T12:47:59.438915Z","iopub.status.idle":"2023-08-13T12:47:59.709616Z","shell.execute_reply.started":"2023-08-13T12:47:59.438882Z","shell.execute_reply":"2023-08-13T12:47:59.708508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"moviesData=moviesData.drop_duplicates(subset='movieid')\nmergedTrain=pd.merge(trainingData, moviesData, on='movieid', how='left')\nmergedTrain.info()\nmergedTest=pd.merge(testingData,moviesData,on='movieid',how='left')\nmergedTest.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:47:59.711013Z","iopub.execute_input":"2023-08-13T12:47:59.711368Z","iopub.status.idle":"2023-08-13T12:48:00.431524Z","shell.execute_reply.started":"2023-08-13T12:47:59.711337Z","shell.execute_reply":"2023-08-13T12:48:00.430350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mergedTrain.describe())\nprint(mergedTest.describe())","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:00.434128Z","iopub.execute_input":"2023-08-13T12:48:00.434457Z","iopub.status.idle":"2023-08-13T12:48:00.475959Z","shell.execute_reply.started":"2023-08-13T12:48:00.434431Z","shell.execute_reply":"2023-08-13T12:48:00.475219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=['movieid','reviewerName','isFrequentReviewer','reviewText','audienceScore','rating','runtimeMinutes','genre','originalLanguage','director','boxOffice','sentiment']\ntestfeatures=['movieid','reviewerName','isFrequentReviewer','reviewText','audienceScore','rating','runtimeMinutes','genre','originalLanguage','director','boxOffice']","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:00.477119Z","iopub.execute_input":"2023-08-13T12:48:00.477457Z","iopub.status.idle":"2023-08-13T12:48:00.482826Z","shell.execute_reply.started":"2023-08-13T12:48:00.477431Z","shell.execute_reply":"2023-08-13T12:48:00.481237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedTrain=mergedTrain[features].copy()\nmergedTrain.isnull().sum()\nmergedTest['isFrequentReviewer']=mergedTest['isTopCritic']\nmergedTest=mergedTest[testfeatures].copy()\nmergedTest.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:00.484522Z","iopub.execute_input":"2023-08-13T12:48:00.484873Z","iopub.status.idle":"2023-08-13T12:48:00.918923Z","shell.execute_reply.started":"2023-08-13T12:48:00.484844Z","shell.execute_reply":"2023-08-13T12:48:00.917580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,f1_score, classification_report,confusion_matrix,precision_recall_curve,roc_curve\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, RobustScaler, LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:00.920356Z","iopub.execute_input":"2023-08-13T12:48:00.920744Z","iopub.status.idle":"2023-08-13T12:48:01.147257Z","shell.execute_reply.started":"2023-08-13T12:48:00.920716Z","shell.execute_reply":"2023-08-13T12:48:01.145591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedTrain['audienceScore'].fillna(mergedTrain['audienceScore'].mean(),inplace=True)\nmergedTrain['runtimeMinutes'].fillna(mergedTrain['runtimeMinutes'].mean(),inplace=True)\n\nmergedTrain['rating'].fillna(mergedTrain['rating'].mode()[0],inplace=True)\nmergedTrain['genre'].fillna(mergedTrain['genre'].mode()[0],inplace=True)\nmergedTrain['originalLanguage'].fillna(mergedTrain['originalLanguage'].mode()[0],inplace=True)\nmergedTrain['boxOffice'].fillna(mergedTrain['boxOffice'].mode()[0],inplace=True)\n\nmergedTrain.isnull().sum()\n\nmergedTest['audienceScore'].fillna(mergedTest['audienceScore'].mean(),inplace=True)\nmergedTest['runtimeMinutes'].fillna(mergedTest['runtimeMinutes'].mean(),inplace=True)\n\nmergedTest['rating'].fillna(mergedTest['rating'].mode()[0],inplace=True)\nmergedTest['genre'].fillna(mergedTest['genre'].mode()[0],inplace=True)\nmergedTest['originalLanguage'].fillna(mergedTest['originalLanguage'].mode()[0],inplace=True)\nmergedTest['boxOffice'].fillna(mergedTest['boxOffice'].mode()[0],inplace=True)\n\nmergedTest.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:01.148626Z","iopub.execute_input":"2023-08-13T12:48:01.148991Z","iopub.status.idle":"2023-08-13T12:48:01.532667Z","shell.execute_reply.started":"2023-08-13T12:48:01.148962Z","shell.execute_reply":"2023-08-13T12:48:01.531591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.histplot(mergedTrain['runtimeMinutes'],bins=30,kde=True)\nplt.xlabel(\"Runtime\")\nplt.ylabel(\"Value\")\nplt.show()\n\n\nplt.figure(figsize=(10,6))\nsns.heatmap(mergedTrain.corr(),annot=True)\nplt.show()\n\n\nplt.figure(figsize=(10,6))\nsns.histplot(mergedTrain['audienceScore'],bins=30,kde=True)\nplt.xlabel(\"Audience Score\")\nplt.ylabel(\"Value\")\nplt.show()\n\n\nmost_common_genres=mergedTrain['genre'].value_counts().nlargest(10)\ntopGenres=mergedTrain[mergedTrain['genre'].isin(most_common_genres.index)]\nplt.figure(figsize=(10,6))\nsns.barplot(x=most_common_genres.index,y=most_common_genres.values)\nplt.xlabel('Genre')\nplt.ylabel('Value')\nplt.xticks(rotation=45)\nplt.show()\n\nmost_common_languages=mergedTrain['originalLanguage'].value_counts().nlargest(10)\ntopLanguages=mergedTrain[mergedTrain['originalLanguage'].isin(most_common_languages.index)]\nplt.figure(figsize=(10,6))\nsns.barplot(x=most_common_languages.index,y=most_common_languages.values)\nplt.xlabel('Language')\nplt.ylabel('Value')\nplt.xticks(rotation=45)\nplt.show()\n\npositive_count = trainingData[\"sentiment\"].eq(\"POSITIVE\").sum()\nnegative_count = trainingData[\"sentiment\"].eq(\"NEGATIVE\").sum()\n\nsizes = [positive_count, negative_count]\nlabels = ['Positive', 'Negative']\ncolors = ['#66b3ff', '#ff9999']\n\nplt.figure(figsize=(6, 6))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\nplt.title('Sentiment Ratio: Positives vs. Negatives')\nplt.axis('equal')  \n\nplt.show()\n\nmissing_values = mergedTrain.isnull().sum()\nprint(missing_values)\n\nsns.heatmap(mergedTrain.isnull(), cbar=False, cmap='viridis')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:01.534315Z","iopub.execute_input":"2023-08-13T12:48:01.534777Z","iopub.status.idle":"2023-08-13T12:48:06.341227Z","shell.execute_reply.started":"2023-08-13T12:48:01.534750Z","shell.execute_reply":"2023-08-13T12:48:06.340166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=mergedTrain.drop(['sentiment'],axis=1)\ny=mergedTrain['sentiment']\n\nlabenc=LabelEncoder()\ny=labenc.fit_transform(y)\n\nXtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=1)\n\nnumericalFeatures=['audienceScore','runtimeMinutes']\ncategoricalFeatures=['isFrequentReviewer','rating','originalLanguage']\ntextFeatures=['movieid','reviewerName','reviewText','genre','director']\n\nparam_grid = {\n    'logreg__C':[5, 7, 9],  # Example range for C\n    'logreg__max_iter': [1500],\n    'logreg__solver': ['sag','saga'],\n    'logreg__penalty': ['l2']\n}\n\n\ncoltrans=ColumnTransformer([\n    ('scaler',MinMaxScaler(),['audienceScore']),\n    ('rscaler',RobustScaler(),['runtimeMinutes']),\n    ('tfidf',TfidfVectorizer(ngram_range=(1,2)),'reviewText'),\n    ('text1',TfidfVectorizer(),'reviewerName'),\n    ('text2',TfidfVectorizer(),'director'),\n    ('text3',TfidfVectorizer(),'genre'),\n    ('text4',TfidfVectorizer(),'movieid'),\n    ('encoder',OneHotEncoder(handle_unknown='ignore'),categoricalFeatures)\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:06.342533Z","iopub.execute_input":"2023-08-13T12:48:06.342857Z","iopub.status.idle":"2023-08-13T12:48:06.478153Z","shell.execute_reply.started":"2023-08-13T12:48:06.342823Z","shell.execute_reply":"2023-08-13T12:48:06.476696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline1=Pipeline([\n    ('ct',coltrans),\n    ('logreg',LogisticRegression(random_state=1,max_iter=2500))\n])\npipeline1.fit(Xtrain,ytrain)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:48:06.479641Z","iopub.execute_input":"2023-08-13T12:48:06.480732Z","iopub.status.idle":"2023-08-13T12:50:10.761475Z","shell.execute_reply.started":"2023-08-13T12:48:06.480668Z","shell.execute_reply":"2023-08-13T12:50:10.760073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred1=pipeline1.predict(Xtest)\naccuracy1 = accuracy_score(ytest, ypred1)\nprint(\"Accuracy of default Logistic Regressor:\", accuracy1)\nyprob1=pipeline1.predict_proba(Xtest)[:,1]\nprint(classification_report(ytest,ypred1))\nprecision1, recall1, thresholds = precision_recall_curve(ytest,yprob1)\nfpr1, tpr1, thresholds = roc_curve(ytest,yprob1)\nplt.figure()\nplt.plot(recall1,precision1,color='purple')\nplt.title('Precision-Recall Curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.show()\nplt.figure()\nplt.plot(fpr1,tpr1,color='green')\nplt.title('ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:50:10.762742Z","iopub.execute_input":"2023-08-13T12:50:10.763014Z","iopub.status.idle":"2023-08-13T12:50:15.792724Z","shell.execute_reply.started":"2023-08-13T12:50:10.762993Z","shell.execute_reply":"2023-08-13T12:50:15.791538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the model appears to have good precision, recall, and F1-scores for both classes. It has higher precision and recall for class 1, indicating that it is better at identifying positive instances. The weighted average F1-score of 0.83 suggests that the model is performing well overall","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.decomposition import TruncatedSVD\n\npipeline2=Pipeline([\n('ct',coltrans),\n('svd',TruncatedSVD(n_components=1000)),\n('logreg',LogisticRegression(random_state=1,max_iter=500))\n])\n\npipeline2.fit(Xtrain,ytrain)\n\nypred2=pipeline2.predict(Xtest)\naccuracy2 = accuracy_score(ytest, ypred2)\nprint(\"Accuracy of LogReg post TruncatedSVD:\", accuracy2)\nyprob2=pipeline2.predict_proba(Xtest)[:,1]\nprint(classification_report(ytest,ypred2))\nprecision2, recall2, thresholds = precision_recall_curve(ytest,yprob2)\nfpr2, tpr2, thresholds = roc_curve(ytest,yprob2)\nplt.figure()\nplt.plot(recall2,precision2,color='purple')\nplt.title('Precision-Recall Curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.show()\nplt.figure()\nplt.plot(fpr2,tpr2,color='green')\nplt.title('ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:50:15.794325Z","iopub.execute_input":"2023-08-13T12:50:15.794716Z","iopub.status.idle":"2023-08-13T12:59:58.904472Z","shell.execute_reply.started":"2023-08-13T12:50:15.794686Z","shell.execute_reply":"2023-08-13T12:59:58.903105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npipeline1HPT=Pipeline([\n('ct',coltrans),\n('logreg',LogisticRegression(solver='saga',max_iter=1250,random_state=1,C=5))\n])\nprint(\"pipeline processed\")\nrandom_search = GridSearchCV(\n    pipeline1HPT, param_grid=param_grid, cv=2, n_jobs=-1, verbose=True\n)\nprint(\"RandomSearch started\")\nrandom_search.fit(Xtrain,ytrain)\nprint(\"Fit done\")\nbest_pipeline = random_search.best_estimator_\nbest_accuracy = random_search.best_score_\nprint(best_pipeline)\nprint(best_accuracy)\n\nypred1HPT=random_search.predict(Xtest)\naccuracy1HPT = accuracy_score(ytest, ypred1HPT)\nprint(\"Accuracy of LogReg HPT:\", accuracy1HPT)\nyprob1HPT=random_search.predict_proba(Xtest)[:,1]\nprint(classification_report(ytest,ypred1HPT))\nprecision3, recall3, thresholds = precision_recall_curve(ytest,yprob1HPT)\nfpr3, tpr3, thresholds = roc_curve(ytest,yprob1HPT)\nplt.figure()\nplt.plot(recall3,precision3,color='purple')\nplt.title('Precision-Recall Curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.show()\nplt.figure()\nplt.plot(fpr3,tpr3,color='green')\nplt.title('ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()\n\n\n\ny_pred=random_search.predict(mergedTest)\nsubmission_df=pd.DataFrame(columns=['id','sentiment'])\nsubmission_df['id']=[i for i in range(len(y_pred))]\nsubmission_df['sentiment']=labenc.inverse_transform(y_pred)\nsubmission_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T12:59:58.906938Z","iopub.execute_input":"2023-08-13T12:59:58.907507Z","iopub.status.idle":"2023-08-13T13:21:49.883001Z","shell.execute_reply.started":"2023-08-13T12:59:58.907478Z","shell.execute_reply":"2023-08-13T13:21:49.880773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the model is performing well. It achieves a good balance between precision and recall, with reasonably high F1-scores for both classes.","metadata":{}},{"cell_type":"markdown","source":"**SVC**","metadata":{}},{"cell_type":"code","source":"\npipeline3=Pipeline([\n    ('ct',coltrans),\n    ('svc',LinearSVC(random_state=1,max_iter=2500,C=0.5))\n])\npipeline3.fit(Xtrain,ytrain)\n\n\nypred3=pipeline3.predict(Xtest)\naccuracy3 = accuracy_score(ytest, ypred3)\nprint(\"Accuracy of LinSVC HPT:\", accuracy3)\nconf_matrix = confusion_matrix(ytest, ypred3)\nprint(conf_matrix)\nprecision4, recall4, _ = precision_recall_curve(ytest, ypred3)\n\n# ROC Curves\nfpr4, tpr4, _ = roc_curve(ytest, ypred3)\n\nplt.figure(figsize=(12, 6))\n\n# Precision-Recall Curve\nplt.subplot(1, 2, 1)\nplt.plot(recall4, precision4, color='purple', label='Model 3')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()\n\n# ROC Curve\nplt.subplot(1, 2, 2)\nplt.plot(fpr4, tpr4, color='green', label='Model 3')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# y_pred3=pipeline3.predict(mergedTest)\n# submission_df=pd.DataFrame(columns=['id','sentiment'])\n# submission_df['id']=[i for i in range(len(y_pred3))]\n# submission_df['sentiment']=labenc.inverse_transform(y_pred3)\n# submission_df.to_csv('submission.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T13:21:49.885681Z","iopub.execute_input":"2023-08-13T13:21:49.886088Z","iopub.status.idle":"2023-08-13T13:24:23.802746Z","shell.execute_reply.started":"2023-08-13T13:21:49.886054Z","shell.execute_reply":"2023-08-13T13:24:23.801219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,ypred3))","metadata":{"execution":{"iopub.status.busy":"2023-08-13T13:24:23.804319Z","iopub.execute_input":"2023-08-13T13:24:23.804687Z","iopub.status.idle":"2023-08-13T13:24:23.852291Z","shell.execute_reply.started":"2023-08-13T13:24:23.804659Z","shell.execute_reply":"2023-08-13T13:24:23.851325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a noticeable difference between the precision and recall values for class 0.The F1-scores indicate that the model's performance is relatively balanced between the two classes.The precision values indicate that the model is about 77% accurate when predicting class 0 and about 79% accurate when predicting class 1.The model's recall for class 0 is significantly lower than its recall for class 1, indicating that it has a harder time identifying instances of class 0 (Class imbalance). Worse than LogReg","metadata":{}},{"cell_type":"markdown","source":"**SGDClf**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n# pipeline4=Pipeline([\n#     ('ct',coltrans),\n#     ('mnb',MultinomialNB(alpha=0.3))\n# ])\n# pipeline4.fit(Xtrain,ytrain)\n\n\n# ypred4=pipeline4.predict(Xtest)\n\n# y_log_probs4 = pipeline4.predict_log_proba(Xtest)\n# precision4, recall4, _ = precision_recall_curve(ytest, y_log_probs4[:, 1])  # Use the positive class log probabilities\n\n# # ROC Curves\n# fpr4, tpr4, _ = roc_curve(ytest, y_log_probs4[:, 1])  # Use the positive class log probabilities\n\n# plt.figure(figsize=(12, 6))\n\n# # Precision-Recall Curve\n# plt.subplot(1, 2, 1)\n# plt.plot(recall4, precision4, color='purple', label='Model 4')\n# plt.xlabel('Recall')\n# plt.ylabel('Precision')\n# plt.title('Precision-Recall Curve')\n# plt.legend()\n\n# # ROC Curve\n# plt.subplot(1, 2, 2)\n# plt.plot(fpr4, tpr4, color='green', label='Model 4')\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.title('ROC Curve')\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n# '''\n# y_pred3=pipeline3.predict(mergedTest)\n# submission_df=pd.DataFrame(columns=['id','sentiment'])\n# submission_df['id']=[i for i in range(len(y_pred3))]\n# submission_df['sentiment']=labenc.inverse_transform(y_pred3)\n# submission_df.to_csv('submission.csv',index=False)\n\n# '''\n\npipeline4 = Pipeline([\n    ('ct', coltrans),\n    ('sgd', SGDClassifier(loss='modified_huber', max_iter=100, tol=0.001, random_state=1, verbose=1))\n])\n\npipeline4.fit(Xtrain, ytrain)\n\n# Predictions\nypred4 = pipeline4.predict(Xtest)\naccuracy4 = accuracy_score(ytest, ypred4)\nprint(\"Accuracy of SGD Classifier:\", accuracy4)\ndecision_scores4 = pipeline4.decision_function(Xtest)\n# Calculate decision function scores using predict_proba\ny_probs4 = pipeline4.predict_proba(Xtest)\n\n# Precision-Recall Curves\nprecision5, recall5, _ = precision_recall_curve(ytest, decision_scores4)\n\n# ROC Curves\nfpr5, tpr5, _ = roc_curve(ytest, decision_scores4)\n\nplt.figure(figsize=(12, 6))\n\n# Precision-Recall Curve\nplt.subplot(1, 2, 1)\nplt.plot(recall5, precision5, color='purple', label='SGDClf Model')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()\n\n# ROC Curve\nplt.subplot(1, 2, 2)\nplt.plot(fpr5, tpr5, color='green', label='SGDClf Model')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n'''\ny_pred4=pipeline4.predict(mergedTest)\nsubmission_df=pd.DataFrame(columns=['id','sentiment'])\nsubmission_df['id']=[i for i in range(len(y_pred4))]\nsubmission_df['sentiment']=labenc.inverse_transform(y_pred4)\nsubmission_df.to_csv('submission.csv',index=False)'''","metadata":{"execution":{"iopub.status.busy":"2023-08-13T13:24:23.853359Z","iopub.execute_input":"2023-08-13T13:24:23.853694Z","iopub.status.idle":"2023-08-13T13:24:48.568965Z","shell.execute_reply.started":"2023-08-13T13:24:23.853670Z","shell.execute_reply":"2023-08-13T13:24:48.568170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,ypred4))","metadata":{"execution":{"iopub.status.busy":"2023-08-13T13:24:48.570190Z","iopub.execute_input":"2023-08-13T13:24:48.570656Z","iopub.status.idle":"2023-08-13T13:24:48.619606Z","shell.execute_reply.started":"2023-08-13T13:24:48.570630Z","shell.execute_reply":"2023-08-13T13:24:48.618562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Better than LinSVC. The model demonstrates balanced performance with respect to precision and recall for both classes. the weighted average F1-score is slightly higher than the accuracy, suggesting that the model's performance is relatively balanced across classes","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(recall1, precision1, color='purple', label='Model 1: LogReg')\nplt.plot(recall2, precision2, color='blue', label='Model 2: PCALogReg')\nplt.plot(recall3, precision3, color='green', label='Model 3: HPTLogReg')\nplt.plot(recall4, precision4, color='red', label='Model 4: LinSVC')\nplt.plot(recall5, precision5, color='orange', label='Model 5: SGDClassifier')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T13:24:48.621143Z","iopub.execute_input":"2023-08-13T13:24:48.621553Z","iopub.status.idle":"2023-08-13T13:24:49.145523Z","shell.execute_reply.started":"2023-08-13T13:24:48.621520Z","shell.execute_reply":"2023-08-13T13:24:49.144235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(1, 2, 2)\n\n# Plotting all ROC curves\nplt.plot(fpr1, tpr1, color='purple', label='Model 1: LogReg')\nplt.plot(fpr2, tpr2, color='blue', label='Model 2: PCALogReg')\nplt.plot(fpr3, tpr3, color='green', label='Model 3: HPTLogReg')\nplt.plot(fpr4, tpr4, color='red', label='Model 4: LinSVC')\nplt.plot(fpr5, tpr5, color='orange', label='Model 5: SGDClassifier')\n\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T13:24:49.147758Z","iopub.execute_input":"2023-08-13T13:24:49.148956Z","iopub.status.idle":"2023-08-13T13:24:49.628174Z","shell.execute_reply.started":"2023-08-13T13:24:49.148866Z","shell.execute_reply":"2023-08-13T13:24:49.627267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\n\n\n# Calculate F1-scores for each model\nf1_scores = [\n    f1_score(ytest, ypred1), #Default\n    f1_score(ytest, ypred2), #LogRegPCA\n    f1_score(ytest, ypred1HPT), #LogRegHPT\n    f1_score(ytest, ypred3), #LinSVC\n    f1_score(ytest,ypred4) #SGDClf\n]\n\nmodels = ['Default Logistic Regressor','Logistic Regressor after SVD', 'Tuned Logistic Regressor', 'LinearSVC', 'SGD Classifier']\n\n# Plotting\nplt.figure(figsize=(10, 6))\n\nplt.bar(models, [accuracy1, accuracy2, accuracy1HPT, accuracy3, accuracy4], label='Accuracy', color='blue')\n#plt.bar(models, f1_scores, label='F1-Score', color='orange', alpha=0.7)\n\nplt.xlabel('Models')\nplt.ylabel('Scores')\nplt.title('Accuracy and F1-Score Comparison')\nplt.legend()\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:20:57.377439Z","iopub.execute_input":"2023-08-13T14:20:57.377888Z","iopub.status.idle":"2023-08-13T14:20:57.674532Z","shell.execute_reply.started":"2023-08-13T14:20:57.377851Z","shell.execute_reply":"2023-08-13T14:20:57.673224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.xticks(rotation=45)\nplt.bar(models, f1_scores, label='F1-Score', color='orange', alpha=0.7)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:21:02.432652Z","iopub.execute_input":"2023-08-13T14:21:02.433031Z","iopub.status.idle":"2023-08-13T14:21:02.600162Z","shell.execute_reply.started":"2023-08-13T14:21:02.433003Z","shell.execute_reply":"2023-08-13T14:21:02.599227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}